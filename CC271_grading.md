# Course grading breakdown

## Summary
| Assignment | Assigned date | Assignment Type | Deliverable | Points | Percentage |
|------------|---------------|-----------------|----------|--------|------------|
| Sankey assignment | 6-Jan | Individual | Document + canvas post | 30 | 7% |
| TEA assignment | 7-Jan | Individual | Document | 30 | 7% |
| Transit trends | 7-Jan | Group | 5 min presentation + 5 min Q&A | 40 | 10% |
| NZA assignment | 8-Jan | Group | 8 min presentation + 2 min Q&A | 40 | 10% |
| LCA assignment | 9-Jan | Individual | Document | 30 | 7% |
| Lecture post | 9-Jan | Individual | Canvas post | 20 | 5% |
| Proposal | 10-Jan | Final Project | 1-page document | 25 | 6% |
| Career assignment | 13-Jan | Individual | 2 min presentation + 1 min Q&A | 25 | 6% |
| Field trip | 14-Jan | Field trip | Attendance | 20 | 5% |
| Final project | 16-Jan | Final Project | 15 min presentation + 5 min Q&A | 121 | 29% |
| Participation | 6-Jan | Participation | Your thoughts | 40 | 10% |

## Individual assignments
Each assignment is graded for:
1. Completeness: Attempts were made on every problem (50%)

2. Quality of answer: Numerical answers are in the right ballpark, qualitative answers make sound arguments (50%). 

Below is a general rubric for how quality will be assessed:
**Unsatisfactory** - Final numbers are orders of magnitude off or calculations have clear unit / dimensional errors in them.
**Satisfactory** - Numbers are reasonable, unit analysis is sound, more could have been done to support conclusions, either by citing sources, or making quantitative arguments where possible.
**Exemplary** - Final numbers look correct, unit analysis is clearly done right, sources are cited, open-ended questions are answered with quantitative arguments. Multiple sources of information are critically looked at (are these trust-worthy sources?), information is synthesized in a coherent way.

## Group assignments
Each assignment is graded based on:
1. Completeness: Presentations were given on the material (50%)
2. Instructor evaluation: I will assess presentation quality with a provided rubric (30%)
3. Received peer evaluation: Class members outside of your group will rate the quality of your presentation with a rubric and free-form questions(15%)
4. Given peer evaluation: Thoughtfulness of your free-form responses in evaluating other groups (5%)

We are trying to cover a lot of material in a short amount of time. We are relying on breakout groups to do "deep-dives" and distill the content for a larger audience.

Group sizes: 3-4 people will be assigned a group. I will be assigning groups to ensure a spread of majors and class years across groups.

## Group final project proposal
Groups will be given a single grade for the quality of their proposals. Proposals will be written 1-pager.

## Group final project
Learning objective:
Propose a new climate technology solution in agriculture emissions mitigation or carbon removal. If successful students will demonstrate the ability to:

- answer the "heilmeyer questions" in a clear, direct manner
- support their arguments with "gut-check" back-of-the-envelope calculations using dimensional analysis
- clearly lay out any assumptions they are making, and be able to support those assumptions
- appropriately synthesize and build upon data / analyses from trusted sources
- quantify potential climate impacts (GHG emission reductions or GHG removal) and other potential "co-benefits"

### Evaluation criteria
Answering the Heilmeyer questions:
1. Is the problem / opportunity well-defined and quantified? (25%)
    - How is it done today?
    - What is the overall market size? (if you can address this problem, how big of a difference will it make)
    - What is the **addressable** market size? (How much of this problem can you realistically address)
2. Is the proposed solution / technology clear? (30%)
    - What is being proposed?
    - How does this solve the problem?
    - Is this approach quantifiably better than existing approaches?
    - If that isn't answerable, what analysis / research would need to be done to answer that question?
3. Is the analysis of impact clear? Make clear what assumptions are made, why they are okay to make, etc. (20%)
    - Taking either a bottom-up or top-down approach, can you quantify the potential impact (i.e. upper bound) of your solution?
    - What is a more realistic impact in the near (< 5 year), medium (10 year) and long (15+ year) term?
4. What would it take to build this? Who is on your team? What risks will you face? How do you mitigate these? (15%)
    - Did the group do a competetive landscape analysis? What other possible solutions are there to the problem, not necessarily today, but coming down the pipeline.
    - Does the group understand what it would take to build what is being proposed? What kinds of engineers do they need?
    - In the process of development, what kinds of risks do you foresee? Are there mitigation strategies that can let you get by while you figure out a long-term solution?
    - Identify where the core IP lies. i.e. what will you do that competitors won't easily be able to replicate?
5. What is the long-term strategy? (10%)
    - How does this solution scale up to maximize impact?
    - What are the intermediate milestones

## Class Participation
Grading for:
1. Attendance (50%)
2. Active class member, asks questions, raise issues (50%)

## Field-trip participation
Grading for:
1. Attendance (100%)